# Лабораторная работа: Параллельное умножение матриц

## Описание

Данная лабораторная работа посвящена исследованию параллельного умножения матриц с использованием библиотеки Python Multiprocessing.

## Вариант задания

- **Заполнение матриц**: Разделяй и властвуй
- **Библиотека**: Python Multiprocessing
- **Алгоритм умножения**: Умножение матриц с переупорядочиванием матрицы

## Структура проекта

```
matrix_lab/
├── matrix_multiply.py      # Основные алгоритмы умножения матриц
├── experiment.py           # Скрипт для проведения экспериментов
├── requirements.txt        # Зависимости проекта
└── README.md              # Документация
```

## Установка зависимостей

```bash
pip install -r requirements.txt
```

## Запуск экспериментов

### Основные эксперименты (размеры до 10000)

```bash
python experiment.py
```

### Расширенные эксперименты (размеры до 100000)

**ВНИМАНИЕ**: Может занять очень много времени и требует много памяти!

```bash
python run_extended_experiments.py
```

## Реализованные алгоритмы

### 1. Заполнение матриц (Разделяй и властвуй)

Метод `fill_matrix_divide_conquer()` рекурсивно разделяет матрицу на 4 подматрицы и заполняет каждую независимо, затем объединяет результаты.

### 2. Умножение матриц с переупорядочиванием

- **Последовательная версия**: `multiply_matrices_sequential()`
- **Параллельная версия**: `multiply_matrices_parallel()`
- **Варианты линеаризации циклов**:
  - `multiply_matrices_linearized_v1()` - линеаризация (i, k, j)
  - `multiply_matrices_linearized_v2()` - линеаризация (k, i, j)
  - `multiply_matrices_linearized_v3()` - линеаризация (j, i, k)

### 3. Переупорядочивание матрицы

Метод `reorder_matrix_for_cache()` транспонирует матрицу для оптимизации доступа к данным и улучшения кэш-локальности.

## Проводимые эксперименты

### Эксперимент 1: Зависимость скорости от количества потоков

Исследует, как изменяется время выполнения умножения матриц в зависимости от количества используемых процессов (от 1 до количества ядер CPU).

**Результаты сохраняются в**: `results_threads.csv`

### Эксперимент 2: Зависимость скорости от размерности матрицы

Исследует, как изменяется время выполнения для матриц различных размеров (от 10x10 до 5000x5000).

**Результаты сохраняются в**: `results_size.csv`

### Эксперимент 3: Сравнение вариантов линеаризации циклов

Сравнивает производительность различных вариантов линеаризации циклов для выбора оптимального.

**Результаты сохраняются в**: `results_linearization.csv`

### Вывод формулы для оценки времени выполнения

На основе результатов экспериментов выводится эмпирическая формула вида:

```
T(n, p) = a * n^b / p^c
```

где:
- `n` - размерность матрицы
- `p` - количество потоков
- `a, b, c` - коэффициенты, найденные методом наименьших квадратов

**Результаты сохраняются в**: `formula.json`

## Формат выходных данных

### CSV файлы

Все CSV файлы содержат следующие поля:
- `size` - размер матрицы
- `threads` - количество потоков
- `time` - время выполнения (секунды)
- `speedup` - ускорение относительно базовой версии

### JSON файл (formula.json)

```json
{
  "formula": "T(n, p) = a * n^b / p^c",
  "coefficients": {
    "a": 1.23e-9,
    "b": 2.85,
    "c": 0.75
  },
  "r_squared": 0.95
}
```

## Технические детали

- Используется библиотека `multiprocessing` для параллелизации
- Каждый процесс обрабатывает свой диапазон строк результирующей матрицы
- Переупорядочивание матрицы (транспонирование) улучшает кэш-локальность при доступе по столбцам
- Все результаты проверяются на корректность сравнением с эталонным результатом (numpy.dot)

## Примечания

- Для больших матриц (>10000) эксперименты могут занять значительное время
- Рекомендуется запускать на машине с несколькими ядрами CPU для наблюдения эффекта параллелизации
- В Windows необходимо использовать конструкцию `if __name__ == '__main__'` для корректной работы multiprocessing

